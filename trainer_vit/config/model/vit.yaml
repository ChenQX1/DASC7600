model: ViTPytorch
n_patches: 12
hidden_d: 1024  # 768 for ViT baseline, 1024 for ViT-large
h_heads: 12
n_layers: 12
k: 4    # scale multiplier
drop_p: 0.2

ckpt_path: ckpts/vit.pth
use_pretrained: True
transformer_name: L_32_imagenet1k # B_32_imagenet1k, L_32_imagenet1k
